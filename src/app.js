// Pippi Voice App Logic - v1.1.5 (Consulted with Thinking Model)
let isRecording = false;
let apiKey = localStorage.getItem('pippi_gemini_api_key') || '';
let customDict = localStorage.getItem('pippi_custom_dict') || '';
let selectedModel = localStorage.getItem('pippi_selected_model') || 'gemini-2.5-flash';
let selectedSTT = localStorage.getItem('pippi_selected_stt') || 'web-speech';

let recognition = null;
let socket = null;
let audioContext = null;
let processor = null;
let stream = null;

// Deduplication State
let finalTranscript = '';
let processedFinalIndex = 0;
let lastFinalHash = '';

// DOM Elements
const micBtn = document.getElementById('mic-btn');
const statusDot = document.querySelector('.status-dot');
const statusText = document.getElementById('status-text');
const settingsBtn = document.getElementById('settings-btn');
const settingsModal = document.getElementById('settings-modal');
const saveSettingsBtn = document.getElementById('save-settings');
const apiKeyInput = document.getElementById('api-key');
const customDictInput = document.getElementById('custom-dict');
const modelSelect = document.getElementById('model-select');
const sttSelect = document.getElementById('stt-select');
const formatBtn = document.getElementById('format-btn');
const copyBtn = document.getElementById('copy-btn');
const finalOutput = document.getElementById('final-output');
const checkUpdateBtn = document.getElementById('check-update-btn');
const realtimeBuffer = document.getElementById('realtime-buffer');

// Initialize UI
if (apiKey) apiKeyInput.value = apiKey;
if (customDict) customDictInput.value = customDict;
if (selectedModel) modelSelect.value = selectedModel;
if (selectedSTT) sttSelect.value = selectedSTT;

checkUpdateBtn.onclick = () => {
    if ('serviceWorker' in navigator) {
        statusText.innerText = 'æ­£åœ¨æª¢æŸ¥æ›´æ–°...';
        navigator.serviceWorker.getRegistration().then(reg => {
            if (reg) {
                reg.update().then(() => {
                    alert('æª¢æŸ¥å®Œæˆï¼å¦‚æœæœ‰æ–°ç‰ˆæœ¬ï¼Œå®ƒæœƒåœ¨èƒŒæ™¯ä¸‹è¼‰ä¸¦åœ¨ä¸‹æ¬¡é–‹å•Ÿæ™‚ç”Ÿæ•ˆã€‚');
                    window.location.reload();
                });
            } else {
                window.location.reload();
            }
        });
    } else {
        window.location.reload();
    }
};

const togglePasswordBtn = document.createElement('button');
togglePasswordBtn.innerText = 'ğŸ‘ï¸';
togglePasswordBtn.className = 'toggle-btn';
apiKeyInput.parentNode.appendChild(togglePasswordBtn);

togglePasswordBtn.onclick = () => {
    const type = apiKeyInput.getAttribute('type') === 'password' ? 'text' : 'password';
    apiKeyInput.setAttribute('type', type);
    togglePasswordBtn.innerText = type === 'password' ? 'ğŸ‘ï¸' : 'ğŸ™ˆ';
};

if (!apiKey) settingsModal.classList.remove('hidden');

// --- Simple Hash for Content Matching ---
function simpleHash(str) {
    let hash = 0;
    for (let i = 0; i < str.length; i++) {
        hash = ((hash << 5) - hash) + str.charCodeAt(i);
        hash |= 0;
    }
    return hash.toString();
}

// --- Web Speech API Setup ---
if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    recognition = new SpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'zh-TW';

    recognition.onresult = (event) => {
        if (selectedSTT !== 'web-speech') return;
        
        let interimTranscript = '';
        let newFinalSegments = [];
        
        for (let i = 0; i < event.results.length; i++) {
            const result = event.results[i];
            const transcript = result[0].transcript;
            
            if (result.isFinal) {
                // é—œéµï¼šåªè™•ç†ç´¢å¼• >= processedFinalIndex çš„æ–° final çµæœ
                if (i >= processedFinalIndex) {
                    newFinalSegments.push(transcript);
                }
            } else {
                interimTranscript = transcript;
            }
        }
        
        if (newFinalSegments.length > 0) {
            const newText = newFinalSegments.join('');
            const newHash = simpleHash(newText);
            
            // äºŒæ¬¡é˜²è­·ï¼šæŒ‡ç´‹æ¯”å°
            if (newHash !== lastFinalHash) {
                finalTranscript += newText;
                lastFinalHash = newHash;
            }
            processedFinalIndex = event.results.length;
        }

        if (realtimeBuffer) realtimeBuffer.innerText = interimTranscript;
        finalOutput.innerText = (finalTranscript + interimTranscript).trim();
        finalOutput.scrollTop = finalOutput.scrollHeight;
    };

    recognition.onend = () => {
        if (isRecording && selectedSTT === 'web-speech') {
            try { recognition.start(); } catch (e) {}
        }
    };
}

// UI Handlers
settingsBtn.onclick = () => settingsModal.classList.remove('hidden');
saveSettingsBtn.onclick = () => {
    apiKey = apiKeyInput.value.trim();
    customDict = customDictInput.value.trim();
    selectedModel = modelSelect.value;
    selectedSTT = sttSelect.value;
    localStorage.setItem('pippi_gemini_api_key', apiKey);
    localStorage.setItem('pippi_custom_dict', customDict);
    localStorage.setItem('pippi_selected_model', selectedModel);
    localStorage.setItem('pippi_selected_stt', selectedSTT);
    settingsModal.classList.add('hidden');
};

copyBtn.onclick = () => {
    navigator.clipboard.writeText(finalOutput.innerText);
    const originalText = copyBtn.innerText;
    copyBtn.innerText = 'âœ… å·²è¤‡è£½';
    setTimeout(() => copyBtn.innerText = originalText, 2000);
};

micBtn.onclick = () => {
    if (!apiKey && selectedSTT === 'gemini-live') {
        alert('ä½¿ç”¨ Gemini Live å¿…é ˆå…ˆè¨­å®š API Key');
        settingsModal.classList.remove('hidden');
        return;
    }
    if (!isRecording) startRecording();
    else stopRecording();
};

formatBtn.onclick = async () => {
    const text = finalOutput.innerText.trim();
    if (!text) return;
    if (!apiKey) {
        alert('è«‹å…ˆåœ¨è¨­å®šä¸­è¼¸å…¥ Gemini API Key');
        settingsModal.classList.remove('hidden');
        return;
    }
    statusText.innerText = 'æ­£åœ¨æ™ºæ…§æ•´ç†ä¸­...';
    try {
        const formatted = await formatTextWithAI(text);
        if (formatted) {
            finalOutput.innerText = formatted;
            finalTranscript = formatted;
            statusText.innerText = 'æ•´ç†å®Œæˆ';
        }
    } catch (e) {
        statusText.innerText = 'æ•´ç†å¤±æ•—';
        alert(`AI æ•´ç†å¤±æ•—ã€‚\nä½¿ç”¨çš„æ¨¡å‹: ${modelSelect.value}\néŒ¯èª¤è³‡è¨Š: ${e.message}`);
    }
};

async function startRecording() {
    finalTranscript = '';
    processedFinalIndex = 0;
    lastFinalHash = '';
    finalOutput.innerText = '';
    if (realtimeBuffer) realtimeBuffer.innerText = '';
    
    isRecording = true;
    micBtn.classList.add('recording');
    statusDot.classList.add('active');

    if (selectedSTT === 'web-speech') {
        statusText.innerText = 'æ­£åœ¨è†è½ä¸­... (åŸç”Ÿå¼•æ“)';
        recognition.start();
    } else {
        await startGeminiLive();
    }
}

async function stopRecording() {
    isRecording = false;
    micBtn.classList.remove('recording');
    statusDot.classList.remove('active');
    statusText.innerText = 'å·²åœæ­¢';

    if (selectedSTT === 'web-speech') {
        recognition.stop();
    } else {
        stopGeminiLive();
    }
}

// --- Gemini Live WebSocket Logic (Enhanced with Robustness) ---
async function startGeminiLive() {
    try {
        statusText.innerText = 'æ­£åœ¨é€£ç·š Gemini Live...';
        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        
        // æ­£ç¢ºçš„ WebSocket URL æ ¼å¼
        const wsUrl = `wss://generativelanguage.googleapis.com/ws/google.ai.generativelanguage.v1beta.GenericService.BidiGenerateContent?key=${apiKey}`;
        socket = new WebSocket(wsUrl);

        socket.onopen = () => {
            statusText.innerText = 'é€£ç·šæˆåŠŸï¼Œç™¼é€åˆå§‹åŒ–...';
            const setup = {
                setup: { 
                    model: "models/gemini-2.0-flash-exp",
                    generation_config: { 
                        response_modalities: ["TEXT"],
                        temperature: 0.7
                    },
                    system_instruction: {
                        parts: [{ text: "ä½ æ˜¯ Pippi Voice çš„åŠ©ç†ï¼Œè«‹å°‡èªéŸ³è½‰ç‚ºç¹é«”ä¸­æ–‡æ–‡å­—ã€‚" }]
                    }
                }
            };
            socket.send(JSON.stringify(setup));
        };

        socket.onmessage = async (event) => {
            const response = JSON.parse(event.data);
            if (response.setupComplete) {
                statusText.innerText = 'æº–å‚™å°±ç·’ (Gemini Live)';
                setupAudioProcessor();
            }
            if (response.serverContent?.modelTurn?.parts) {
                const text = response.serverContent.modelTurn.parts.map(p => p.text).join('');
                if (text) {
                    finalOutput.innerText += text;
                    finalOutput.scrollTop = finalOutput.scrollHeight;
                }
            }
        };

        socket.onerror = (e) => {
            console.error('WebSocket Error:', e);
            statusText.innerText = 'é€£ç·šå‡ºéŒ¯ï¼Œè«‹æª¢æŸ¥ Key æ¬Šé™';
            alert('Gemini Live é€£ç·šå¤±æ•—ã€‚æ‚¨çš„ API Key å¯èƒ½ä¸æ”¯æ´å³æ™‚ WebSocket æ¬Šé™ã€‚å»ºè­°æ”¹ç”¨ã€Œç€è¦½å™¨åŸç”Ÿã€å¼•æ“ã€‚');
            stopRecording();
        };

        socket.onclose = (e) => {
            if (isRecording) {
                console.log('WebSocket Closed:', e);
                stopRecording();
            }
        };

    } catch (err) {
        alert('ç„¡æ³•å•Ÿå‹• Gemini Liveï¼š' + err.message);
        stopRecording();
    }
}

function stopGeminiLive() {
    if (processor) { processor.disconnect(); processor = null; }
    if (audioContext) { audioContext.close(); audioContext = null; }
    if (stream) { stream.getTracks().forEach(t => t.stop()); stream = null; }
    if (socket) { if (socket.readyState === WebSocket.OPEN) socket.close(); socket = null; }
}

function setupAudioProcessor() {
    audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
    const source = audioContext.createMediaStreamSource(stream);
    processor = audioContext.createScriptProcessor(4096, 1, 1);
    source.connect(processor);
    processor.connect(audioContext.destination);

    processor.onaudioprocess = (e) => {
        if (!isRecording || !socket || socket.readyState !== WebSocket.OPEN) return;
        const inputData = e.inputBuffer.getChannelData(0);
        const pcmData = new Int16Array(inputData.length);
        for (let i = 0; i < inputData.length; i++) {
            const s = Math.max(-1, Math.min(1, inputData[i]));
            pcmData[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
        }
        const uint8Array = new Uint8Array(pcmData.buffer);
        let binary = '';
        for (let i = 0; i < uint8Array.length; i++) binary += String.fromCharCode(uint8Array[i]);
        socket.send(JSON.stringify({
            realtimeInput: { mediaChunks: [{ mimeType: "audio/pcm;rate=16000", data: btoa(binary) }] }
        }));
    };
}

async function formatTextWithAI(text) {
    const model = document.getElementById('model-select').value;
    const prompt = `ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ–‡å­—ç·¨è¼¯ã€‚è«‹å°‡ä»¥ä¸‹èªéŸ³é€å­—ç¨¿é€²è¡Œä¿®å¾©èˆ‡æ ¼å¼åŒ–ã€‚

âš ï¸ **æ¥µé‡è¦è¦å‰‡**ï¼š
1. è«‹ã€Œç›´æ¥è¼¸å‡ºã€æ ¼å¼åŒ–å¾Œçš„çµæœå³å¯ã€‚ç¦æ­¢åŒ…å«ä»»ä½•é–‹å ´ç™½ã€åˆ†æã€èªªæ˜æ–‡å­—ã€‚
2. ä½¿ç”¨æ¸…æ™°çš„æ ¼å¼ï¼šå¦‚æœå…§å®¹é©åˆæ¢åˆ—ï¼Œè«‹ä½¿ç”¨æ¨™æº–ç¬¦è™Ÿï¼ˆå¦‚ â€¢ æˆ– 1. 2. 3.ï¼‰ã€‚

ä»»å‹™æ¸…å–®ï¼š
1. è‡ªå‹•è­˜åˆ¥ä¸¦åŸ·è¡Œã€Œæ›´æ­£ã€ã€ã€ŒèªªéŒ¯äº†ã€ã€ã€Œä¸å°ã€ç­‰å£èªæŒ‡ä»¤ã€‚
2. ä¿®æ­£éŒ¯åˆ¥å­—ä¸¦ä¿æŒç¹é«”ä¸­æ–‡ã€‚
3. ä¿æŒä¸­è‹±æ–‡æ··ç”¨çš„è‡ªç„¶åº¦ã€‚
${customDict ? `4. ç‰¹åˆ¥æ³¨æ„ä»¥ä¸‹å°ˆæœ‰åè©æˆ–å¸¸ç”¨è©çš„æ­£ç¢ºæ‹¼æ³•ï¼š\n${customDict}` : ''}

å¾…è™•ç†å…§å®¹å¦‚ä¸‹ï¼š
${text}`;

    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ contents: [{ parts: [{ text: prompt }] }] })
    });

    if (!response.ok) {
        const errData = await response.json();
        throw new Error(`API éŒ¯èª¤ (${response.status}): ${errData.error?.message || 'æœªçŸ¥éŒ¯èª¤'}`);
    }

    const data = await response.json();
    return data.candidates[0].content.parts[0].text;
}
